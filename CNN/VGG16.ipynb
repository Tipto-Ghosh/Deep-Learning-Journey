{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0e5d3fe-6796-453e-8a3f-62a76bcfe6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f55735a-951a-415a-933b-196875362e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets , transforms\n",
    "from torch.utils.data import DataLoader, random_split,Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af5c6803-a393-4310-b328-ea7f9b114216",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FruitFreshnessDataset(Dataset):\n",
    "    def __init__(self , root_dir , transform = None): \n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "        self.fruit_map = {'Apple': 0, 'Banana': 1, 'Strawberry': 2}\n",
    "        self.freshness_map = {'Fresh': 0, 'Rotten': 1} \n",
    "\n",
    "        for fruit in os.listdir(root_dir): \n",
    "            fruit_path = os.path.join(root_dir , fruit)\n",
    "            \n",
    "            for freshness in os.listdir(fruit_path): \n",
    "                freshness_path = os.path.join(fruit_path , freshness)\n",
    "\n",
    "                for image_file in os.listdir(freshness_path):\n",
    "                    image_file_path = os.path.join(freshness_path , image_file)\n",
    "                    self.images.append(image_file_path)\n",
    "                    self.labels.append((self.fruit_map[fruit] , self.freshness_map[freshness]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "        \n",
    "    def __getitem__(self , index): \n",
    "        image = Image.open(self.images[index]).convert(\"RGB\")\n",
    "        if self.transform: \n",
    "            image = self.transform(image)\n",
    "        return image , self.labels[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8fdd9ad-ca60-461e-8469-0d8341fce5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple', 'Banana', 'Strawberry']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_dir = \"Data/Fruit Freshness Dataset/\"\n",
    "os.listdir(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41ad3aaf-4218-4a81-b05c-b5ec059e8bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # Resize all images to 224x224\n",
    "    transforms.RandomHorizontalFlip(), # augmentation\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "268a9a96-10f2-4788-838c-a96c9d79a307",
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit_dataset = FruitFreshnessDataset(root_dir = root_dir , transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38714ca4-3409-4fe0-b2d5-6f5fc077a688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images: 566\n",
      "Sample image & labels: torch.Size([3, 224, 224]), (0, 0)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total images: {len(fruit_dataset)}\")\n",
    "print(f\"Sample image & labels: {fruit_dataset[0][0].shape}, {fruit_dataset[0][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e43c4af-356d-4980-ae06-d8e8c0f50284",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_size = len(fruit_dataset)\n",
    "train_size = int(0.7 * total_size)\n",
    "val_size = int(0.15 * total_size)\n",
    "test_size = total_size - train_size - val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "430a1e92-b3dc-4992-b03f-6770956f7f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = random_split(fruit_dataset, [train_size, val_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b26fc7e2-2edb-4352-aafa-625daab12f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46fd75a5-fdb5-47cb-8be9-fcad6642ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataloader \n",
    "train_loader = DataLoader(train_dataset , batch_size = batch_size , shuffle = True)\n",
    "val_loader = DataLoader(val_dataset , batch_size = batch_size , shuffle = False)\n",
    "test_loader = DataLoader(test_dataset , batch_size = batch_size , shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adb4b741-e836-4f49-babb-6f862c60fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17d6bb4f-948f-41f6-89f3-2fca2c17e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(weights = models.VGG16_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e08a3ff-cc3c-40b8-909a-d7aa82e18a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (13): ReLU(inplace=True)\n",
       "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (15): ReLU(inplace=True)\n",
       "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (18): ReLU(inplace=True)\n",
       "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (20): ReLU(inplace=True)\n",
       "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (22): ReLU(inplace=True)\n",
       "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (25): ReLU(inplace=True)\n",
       "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (27): ReLU(inplace=True)\n",
       "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (29): ReLU(inplace=True)\n",
       "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Dropout(p=0.5, inplace=False)\n",
       "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): Dropout(p=0.5, inplace=False)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36b5a9f9-a347-4785-a4f6-8e742794595d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_fruit_classes = 3\n",
    "num_freshness_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06ed24c9-1f2f-44cb-b684-57404594da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87ecce6d-caab-41e2-b64c-245b8daedc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25088"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg16.classifier[0].in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c759a932-3836-49f0-8086-3694404a5512",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiOutputVGG16(nn.Module): \n",
    "    def __init__(self , base_model, num_fruit_classes, num_freshness_classes): \n",
    "        super().__init__()\n",
    "        self.features = base_model.features # keeping the convolution layers\n",
    "        # Now freeze the cnn part \n",
    "        for param in self.features.parameters(): \n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Fully connect layers \n",
    "        in_features = base_model.classifier[0].in_features\n",
    "\n",
    "        # Two heads: 1.Fruit type , 2.Freshness \n",
    "        self.fc_fruit = nn.Linear(in_features , num_fruit_classes)\n",
    "        self.fc_freshness = nn.Linear(in_features , num_freshness_classes) \n",
    "\n",
    "    def forward(self , x): \n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0) , -1) # flatten the image\n",
    "        fruit_out = self.fc_fruit(x)\n",
    "        freshness_out = self.fc_freshness(x)\n",
    "        return fruit_out , freshness_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5df42301-c2af-4461-991b-41b2a1c8d426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(vgg16.children()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b00415e-6f29-44b0-bbba-d2b1a6e5a313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(vgg16.children())[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8d247f0-41f0-4c25-8f22-df0858f2f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputVGG16(\n",
    "    base_model = vgg16,\n",
    "    num_fruit_classes = num_fruit_classes,\n",
    "    num_freshness_classes = num_freshness_classes\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a233c71-d3f1-4802-835b-580a90c1732e",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "82a1a860-b370-49b7-a8aa-65e591167ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5 , Loss: 0.8439\n",
      "Epoch: 2/5 , Loss: 0.1834\n",
      "Epoch: 3/5 , Loss: 0.1059\n",
      "Epoch: 4/5 , Loss: 0.0716\n",
      "Epoch: 5/5 , Loss: 0.0526\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs): \n",
    "    model.train()\n",
    "    total_loss = 0 \n",
    "    for images , labels in train_loader: \n",
    "        images = images.to(device)\n",
    "        fruit_labels = labels[0].to(device)\n",
    "        freshness_labels = labels[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        fruit_out, freshness_out = model(images)\n",
    "        loss = criterion(fruit_out, fruit_labels) + criterion(freshness_out, freshness_labels)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        \n",
    "    print(f\"Epoch: {epoch + 1}/{num_epochs} , Loss: {total_loss/len(train_loader.dataset):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2f1475fd-e447-492f-bd9c-bfd16ef9019f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fruit Accuracy: 100.00%\n",
      "Freshness Accuracy: 92.86%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct_fruit = 0\n",
    "correct_freshness = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        fruit_labels = labels[0].to(device)\n",
    "        freshness_labels = labels[1].to(device)\n",
    "\n",
    "        fruit_out, freshness_out = model(images)\n",
    "        _, pred_fruit = torch.max(fruit_out, 1)\n",
    "        _, pred_freshness = torch.max(freshness_out, 1)\n",
    "\n",
    "        total += fruit_labels.size(0)\n",
    "        correct_fruit += (pred_fruit == fruit_labels).sum().item()\n",
    "        correct_freshness += (pred_freshness == freshness_labels).sum().item()\n",
    "\n",
    "print(f\"Fruit Accuracy: {100*correct_fruit/total:.2f}%\")\n",
    "print(f\"Freshness Accuracy: {100*correct_freshness/total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41d9ba09-141a-4b32-b20f-8981898a41ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    classification_report\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7906143b-ac4a-4a0d-b7fe-405dabccae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "true_fruit = []\n",
    "pred_fruit = []\n",
    "true_freshness = []\n",
    "pred_freshness = []\n",
    "\n",
    "prob_freshness = []\n",
    "prob_fruit = [] \n",
    "\n",
    "\n",
    "with torch.no_grad(): \n",
    "    for images , labels in val_loader: \n",
    "        images = images.to(device)\n",
    "        fruit_labels = labels[0].to(device)\n",
    "        freshness_labels = labels[1].to(device)\n",
    "\n",
    "        fruit_out, freshness_out = model(images)\n",
    "\n",
    "        fruit_preds = torch.argmax(fruit_out, dim=1)\n",
    "        freshness_preds = torch.argmax(freshness_out, dim=1)\n",
    "\n",
    "        fruit_probs = torch.softmax(fruit_out, dim=1)\n",
    "        freshness_probs = torch.softmax(freshness_out, dim=1)\n",
    "\n",
    "        true_fruit.extend(fruit_labels.cpu().numpy())\n",
    "        pred_fruit.extend(fruit_preds.cpu().numpy())\n",
    "        true_freshness.extend(freshness_labels.cpu().numpy())\n",
    "        pred_freshness.extend(freshness_preds.cpu().numpy())\n",
    "\n",
    "        prob_freshness.extend(freshness_probs[:, 1].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b58540e2-0047-4727-ae51-9557b89766b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRESHNESS METRICS\n",
      "Accuracy : 0.9285714285714286\n",
      "Precision: 0.9642857142857143\n",
      "Recall   : 0.84375\n",
      "F1 Score : 0.9\n",
      "AUC      : 0.9819711538461539\n"
     ]
    }
   ],
   "source": [
    "print(\"FRESHNESS METRICS\")\n",
    "\n",
    "print(\"Accuracy :\", accuracy_score(true_freshness, pred_freshness))\n",
    "print(\"Precision:\", precision_score(true_freshness, pred_freshness))\n",
    "print(\"Recall   :\", recall_score(true_freshness, pred_freshness))\n",
    "print(\"F1 Score :\", f1_score(true_freshness, pred_freshness))\n",
    "\n",
    "auc = roc_auc_score(true_freshness, prob_freshness)\n",
    "print(\"AUC      :\", auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "330c862e-560b-47b9-8f68-d4c95f90237d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRUIT METRICS\n",
      "Accuracy : 1.0\n",
      "Precision: 1.0\n",
      "Recall   : 1.0\n",
      "F1 Score : 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"FRUIT METRICS\")\n",
    "print(\"Accuracy :\", accuracy_score(true_fruit, pred_fruit))\n",
    "print(\"Precision:\", precision_score(true_fruit, pred_fruit, average=\"macro\"))\n",
    "print(\"Recall   :\", recall_score(true_fruit, pred_fruit, average=\"macro\"))\n",
    "print(\"F1 Score :\", f1_score(true_fruit, pred_fruit, average=\"macro\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python(DL)",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
